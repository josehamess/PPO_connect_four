{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44973,"status":"ok","timestamp":1658233036776,"user":{"displayName":"Joseph Amess","userId":"01893786635442142975"},"user_tz":-60},"id":"SGlPTv7sFXL6","outputId":"954e9085-18fa-448e-d72c-589d111f6ced"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pettingzoo\n","  Downloading PettingZoo-1.19.0-py3-none-any.whl (807 kB)\n","\u001b[K     |████████████████████████████████| 807 kB 5.2 MB/s \n","\u001b[?25hCollecting gym>=0.21.0\n","  Downloading gym-0.25.0.tar.gz (720 kB)\n","\u001b[K     |████████████████████████████████| 720 kB 50.1 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from pettingzoo) (1.21.6)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.21.0->pettingzoo) (1.3.0)\n","Collecting gym-notices>=0.0.4\n","  Downloading gym_notices-0.0.7-py3-none-any.whl (2.7 kB)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.21.0->pettingzoo) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.21.0->pettingzoo) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.21.0->pettingzoo) (3.8.0)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.25.0-py3-none-any.whl size=824431 sha256=aa8fc39e1a3ad6068f7674dd21712aa8c55ae93b46be978e836d996ee404f8e8\n","  Stored in directory: /root/.cache/pip/wheels/2c/58/d8/1590abcfe48cdf414681b1e2b6647045b85f7c924563b664ee\n","Successfully built gym\n","Installing collected packages: gym-notices, gym, pettingzoo\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","Successfully installed gym-0.25.0 gym-notices-0.0.7 pettingzoo-1.19.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pygame\n","  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n","\u001b[K     |████████████████████████████████| 21.8 MB 62.9 MB/s \n","\u001b[?25hInstalling collected packages: pygame\n","Successfully installed pygame-2.1.2\n","Mounted at /content/drive\n"]}],"source":["!pip install pettingzoo\n","!pip install pygame\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from pettingzoo.classic import connect_four_v3\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.distributions.categorical import Categorical\n","from torch.nn.modules.activation import LeakyReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BU4erA8YFXL8"},"outputs":[],"source":["class Actor(nn.Module):\n","    def __init__(self, n_actions, drop_out):\n","        super(Actor, self).__init__()\n","        self.n_actions = n_actions\n","        self.drop_out = drop_out\n","\n","        self.actor = nn.Sequential(\n","                nn.Conv2d(1, 24, 3, padding=1),\n","                nn.LeakyReLU(),\n","                nn.Conv2d(24, 64, 3),\n","                nn.LeakyReLU(),\n","                nn.Conv2d(64, 128, 3),\n","                nn.LeakyReLU(),\n","                nn.Conv2d(128, 256, 4),\n","                nn.Flatten(start_dim=1, end_dim=-1),\n","                nn.LeakyReLU(),\n","                nn.Linear(256, self.n_actions),\n","                nn.Softmax(dim=-1)\n","                )\n","    \n","    def forward(self, state, action_mask):\n","        dist = self.actor(state.float()) * action_mask\n","        dist = dist / torch.sum(dist) + 1e-7\n","        dist = Categorical(dist)\n","        return dist\n","\n","\n","class Critic(nn.Module):\n","    def __init__(self, drop_out):\n","        super(Critic, self).__init__()\n","        self.drop_out = drop_out\n","\n","        self.critic = nn.Sequential(\n","                nn.Conv2d(1, 24, 3, padding=1),\n","                nn.LeakyReLU(),\n","                nn.Conv2d(24, 64, 3),\n","                nn.LeakyReLU(),\n","                nn.Conv2d(64, 128, 3),\n","                nn.LeakyReLU(),\n","                nn.Conv2d(128, 256, 4),\n","                nn.Flatten(start_dim=1, end_dim=-1),\n","                nn.LeakyReLU(),\n","                nn.Linear(256, 1)\n","                )\n","    \n","    def forward(self, state):\n","        value = self.critic(state.float())\n","        return value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aFbVzyNoFXL-"},"outputs":[],"source":["def clean_memory():\n","\n","    #initialise agent memory dict\n","    agent_memory = {}\n","\n","    #returns clean memory lists\n","    \n","    agent_memory['probs'] = []\n","    agent_memory['values'] = []\n","    agent_memory['obs'] = []\n","    agent_memory['rewards'] = []\n","    agent_memory['actions'] = []\n","    agent_memory['action_masks'] = []\n","    agent_memory['dones'] = []\n","\n","    return agent_memory\n","\n","\n","def choose_action(observation, action_mask, actor):\n","    \n","    #returns a log probability of taking the action as well as the acion\n","\n","    dist = actor(torch.tensor(observation), torch.tensor(action_mask))\n","\n","    #sample action from distribution\n","    action = dist.sample()\n","\n","    prob = torch.squeeze(dist.log_prob(action)).item()\n","    action = torch.squeeze(action).item()\n","\n","    return action, prob\n","\n","\n","def advantage_calc(values, rewards, dones, lambda_, gamma):\n","\n","    # returns a list containing the advantages for each timestep\n","\n","    advantages = []\n","\n","    # iterate over each timestep\n","    for i in range(len(rewards) - 1):\n","\n","        # initialise advantage for timestep t and discount\n","        A_t = 0\n","        discount = 1.0\n","\n","        # at each timestep iterate to the end of episode or block of timesteps\n","        for j in range(i, len(rewards) - 1):\n","\n","            # calculate TD error\n","            # if done is true then no t + 1 val will exist so TD error is simply\n","            # reward at t minus value at t\n","            if dones[j] == True:\n","                TD_error = rewards[j] - values[j]\n","            \n","            # if not done then can take value from t + 1 into the future\n","            else:\n","                TD_error = rewards[j] + (gamma * values[j + 1]) - values[j]\n","            \n","            # add to advatage for iter i\n","            A_t += TD_error * discount\n","\n","            # update discount with smoothing and discount gamma\n","            discount *= (lambda_ * gamma)\n","            \n","            # if the epsiode is finished then break advantage update\n","            # it would not make sense to continue with discounted value \n","            # at the start of the next episode\n","            if dones[j] == True:\n","                break\n","        \n","        # update advantage list\n","        advantages.append(A_t)\n","    \n","    # complete advantage list with zero at end\n","    advantages.append(0.0)\n","    \n","    return advantages\n","\n","\n","def batch_builder(probs, values, obs, rewards, actions, advantages, action_masks, batch_size):\n","\n","    #returns a list of dictionaries where each dictionary contains lists of\n","    #memories of length batch size\n","\n","    #get random indices\n","    indices = list(range(0, len(rewards)))\n","    np.random.shuffle(indices)\n","\n","    batches = []\n","\n","    #iterate as many times as full batches can be created\n","    for i in range(0, len(rewards), batch_size):\n","\n","        #make sure batch size is correct size\n","        if len(rewards) - i < batch_size:\n","            continue\n","        \n","        #collect all information in a batch dictionary and append to batch list\n","        batch_indices = indices[i:i + batch_size]\n","        batch_dict = {  'observations': np.expand_dims(np.array([obs[index] for index in batch_indices]), 1), \n","                        'actions':      [actions[index] for index in batch_indices], \n","                        'probs':        [probs[index] for index in batch_indices], \n","                        'values':       [values[index] for index in batch_indices], \n","                        'rewards':      [rewards[index] for index in batch_indices], \n","                        'masks':        [action_masks[index] for index in batch_indices],\n","                        'advantages':   [advantages[index] for index in batch_indices]}\n","        batches.append(batch_dict)\n","    \n","    return batches\n","\n","\n","def train(actor, critic, actor_optimiser, critic_optimiser, batches, clip, c1):\n","\n","    #returns the trained actor and critic model\n","\n","    #iterate through batches\n","    for batch in batches:\n","        \n","        #calculate critic loss using mean MSE\n","        current_values = torch.squeeze(critic(torch.tensor(batch['observations'])))\n","        returns = torch.squeeze(torch.tensor(batch['advantages']) + torch.tensor(batch['values']))\n","        critic_loss = (returns - current_values) ** 2\n","        critic_loss = critic_loss.mean()\n","\n","        #calculate actor loss using clipped probs ratio and advantages\n","        dist = actor(torch.tensor(batch['observations']), torch.tensor(batch['masks']))\n","        new_probs = dist.log_prob(torch.tensor(batch['actions']))\n","        prob_ratio = new_probs.exp() / torch.tensor(batch['probs']).exp()\n","        unclipped_loss = torch.tensor(batch['advantages']) * prob_ratio\n","        clipped_loss = torch.clamp(prob_ratio, 1 - clip, 1 + clip) * torch.tensor(batch['advantages'])\n","        #negative as trying to maximise value\n","        actor_loss = -torch.min(unclipped_loss, clipped_loss).mean()\n","\n","        #add losses together\n","        total_loss = actor_loss + (c1 * critic_loss)\n","\n","        #update weights\n","        actor_optimiser.zero_grad()\n","        critic_optimiser.zero_grad()\n","        total_loss.backward()\n","        actor_optimiser.step()\n","        critic_optimiser.step()\n","    \n","    return actor, critic\n","\n","\n","def reshape_image(observation):\n","\n","    # returns the observation array after padding, transposing channnel\n","    # and adding extra dimension\n","\n","    #pad observation to make square\n","    padded_observation = np.pad(observation, [(1, 1), (1, 0), (0, 0)])\n","\n","    #transpose to get channel first\n","    transposed_observation = np.transpose(padded_observation, (2, 0, 1))\n","\n","    #compress observation to one channel\n","    compressed_observation = transposed_observation[0, :, :] + (-1 * transposed_observation[1, :, :])\n","\n","    #reshape to add batch size to the front\n","    reshaped_observation = np.reshape(compressed_observation, \n","                                    (1, 1, compressed_observation.shape[0],\n","                                    compressed_observation.shape[1]))\n","    \n","    return reshaped_observation\n","\n","\n","def rand_action_picker(n_actions, observation):\n","\n","    # returns a random action from the action space\n","\n","    # create and mask action space with plus one so only masked actions appear as 0\n","    action_space = np.array(range(1, n_actions + 1))\n","    action_space_masked = np.array(observation['action_mask']) * action_space\n","\n","    # remove actions that appear as zero then minus 1 from remaining actions\n","    action_space_masked = np.array([x for x in action_space_masked if x > 0]) - 1\n","\n","    # pick a random action from the remaining valid actions\n","    action = action_space_masked[np.random.randint(0, len(action_space_masked))]\n","\n","    return action\n","  \n","\n","def algo_hyperparam_init(limits):\n","\n","    #initialise hyperparameters\n","    algo_hyperparameters = {}\n","\n","    #iterate over hyperparameters\n","    for param in limits:\n","\n","        algo_hyperparameters[param] = np.random.uniform(limits[param][0], limits[param][1])\n","\n","    return algo_hyperparameters\n","\n","\n","def score_dict_init(model_list):\n","\n","    frac_dict = {}\n","    score_dict = {}\n","\n","    for model in model_list:\n","\n","        frac_dict[model] = []\n","        score_dict[model] = []\n","      \n","    return frac_dict, score_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epNUFgHMFXMB","outputId":"bea89705-8c93-49f9-e702-6784261bca15"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["614327\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Episode: 125163, current best loss fractions: [0.01]\n","Episode: 125168, current best loss fractions: [0.01]\n","Episode: 125173, current best loss fractions: [0.01]\n","Episode: 125178, current best loss fractions: [0.01]\n","Episode: 125183, current best loss fractions: [0.01]\n","Episode: 125188, current best loss fractions: [0.01]\n","Episode: 125193, current best loss fractions: [0.01]\n","Episode: 125198, current best loss fractions: [0.01]\n","Episode: 125203, current best loss fractions: [0.01]\n","Episode: 125208, current best loss fractions: [0.01]\n","Episode: 125213, current best loss fractions: [0.01]\n","Episode: 125218, current best loss fractions: [0.01]\n","Episode: 125223, current best loss fractions: [0.01]\n","Episode: 125228, current best loss fractions: [0.01]\n","Episode: 125233, current best loss fractions: [0.01]\n","Episode: 125238, current best loss fractions: [0.01]\n","Episode: 125243, current best loss fractions: [0.01]\n","Episode: 125248, current best loss fractions: [0.01]\n","Episode: 125253, current best loss fractions: [0.01]\n","Episode: 125258, current best loss fractions: [0.01]\n","Episode: 125263, current best loss fractions: [0.01]\n","Episode: 125268, current best loss fractions: [0.01]\n","Episode: 125273, current best loss fractions: [0.01]\n","Episode: 125509, current best loss fractions: [0.01]\n","Episode: 125514, current best loss fractions: [0.01]\n","Episode: 125519, current best loss fractions: [0.01]\n","Episode: 125524, current best loss fractions: [0.01]\n","Episode: 125553, current best loss fractions: [0.01]\n","Episode: 125558, current best loss fractions: [0.01]\n","Episode: 125563, current best loss fractions: [0.01]\n","Episode: 125568, current best loss fractions: [0.01]\n","Episode: 125573, current best loss fractions: [0.01]\n","Episode: 125578, current best loss fractions: [0.01]\n","Episode: 125583, current best loss fractions: [0.01]\n","Episode: 125588, current best loss fractions: [0.01]\n","Episode: 125593, current best loss fractions: [0.01]\n","Episode: 125598, current best loss fractions: [0.01]\n","Episode: 125603, current best loss fractions: [0.01]\n","Episode: 125608, current best loss fractions: [0.01]\n","Episode: 125613, current best loss fractions: [0.01]\n","Episode: 125618, current best loss fractions: [0.01]\n","Episode: 125623, current best loss fractions: [0.01]\n","Episode: 125628, current best loss fractions: [0.01]\n","Episode: 125633, current best loss fractions: [0.01]\n","Episode: 125638, current best loss fractions: [0.01]\n","Episode: 125643, current best loss fractions: [0.0095]\n","Episode: 125648, current best loss fractions: [0.0095]\n","Episode: 125653, current best loss fractions: [0.0095]\n","Episode: 125658, current best loss fractions: [0.0095]\n","Episode: 125676, current best loss fractions: [0.0095]\n","Episode: 125681, current best loss fractions: [0.0095]\n","Episode: 125686, current best loss fractions: [0.0095]\n","Episode: 125691, current best loss fractions: [0.0095]\n","Episode: 125696, current best loss fractions: [0.0095]\n","Episode: 125701, current best loss fractions: [0.0095]\n","Episode: 125706, current best loss fractions: [0.0095]\n","Episode: 125711, current best loss fractions: [0.009]\n","Episode: 125716, current best loss fractions: [0.009]\n","Episode: 125721, current best loss fractions: [0.009]\n","Episode: 125726, current best loss fractions: [0.009]\n","Episode: 125731, current best loss fractions: [0.009]\n","Episode: 125736, current best loss fractions: [0.009]\n","Episode: 125741, current best loss fractions: [0.009]\n","Episode: 125746, current best loss fractions: [0.009]\n","Episode: 125751, current best loss fractions: [0.009]\n","Episode: 125756, current best loss fractions: [0.009]\n","Episode: 125831, current best loss fractions: [0.009]\n","Episode: 126131, current best loss fractions: [0.009]\n","Episode: 126136, current best loss fractions: [0.009]\n","Episode: 126147, current best loss fractions: [0.009]\n","Episode: 126152, current best loss fractions: [0.009]\n","Episode: 126157, current best loss fractions: [0.009]\n","Episode: 126162, current best loss fractions: [0.009]\n","Episode: 126167, current best loss fractions: [0.009]\n","Episode: 126172, current best loss fractions: [0.009]\n","Episode: 126177, current best loss fractions: [0.009]\n","Episode: 126182, current best loss fractions: [0.009]\n","Episode: 126187, current best loss fractions: [0.009]\n","Episode: 126192, current best loss fractions: [0.009]\n","Episode: 126197, current best loss fractions: [0.009]\n","Episode: 126202, current best loss fractions: [0.009]\n","Episode: 126207, current best loss fractions: [0.009]\n","Episode: 126212, current best loss fractions: [0.009]\n","Episode: 126217, current best loss fractions: [0.009]\n","Episode: 126222, current best loss fractions: [0.009]\n","Episode: 149204, current best loss fractions: [0.0085]\n","Episode: 149209, current best loss fractions: [0.0085]\n","Episode: 149214, current best loss fractions: [0.0085]\n","Episode: 149219, current best loss fractions: [0.0085]\n","Episode: 149224, current best loss fractions: [0.0085]\n","Episode: 149229, current best loss fractions: [0.0085]\n","Episode: 149234, current best loss fractions: [0.0085]\n","Episode: 149239, current best loss fractions: [0.0085]\n","Episode: 149244, current best loss fractions: [0.0085]\n","Episode: 149249, current best loss fractions: [0.0085]\n","Episode: 149254, current best loss fractions: [0.0085]\n","Episode: 149259, current best loss fractions: [0.0085]\n","Episode: 149264, current best loss fractions: [0.0085]\n","Episode: 149269, current best loss fractions: [0.0085]\n","Episode: 149274, current best loss fractions: [0.0085]\n","Episode: 149279, current best loss fractions: [0.0085]\n","Episode: 149284, current best loss fractions: [0.0085]\n","Episode: 149289, current best loss fractions: [0.0085]\n","Episode: 149294, current best loss fractions: [0.0085]\n","Episode: 149299, current best loss fractions: [0.0085]\n","Episode: 149304, current best loss fractions: [0.0085]\n","Episode: 149309, current best loss fractions: [0.0085]\n","Episode: 149314, current best loss fractions: [0.0085]\n","Episode: 149319, current best loss fractions: [0.0085]\n","Episode: 149324, current best loss fractions: [0.0085]\n","Episode: 149329, current best loss fractions: [0.0085]\n","Episode: 149334, current best loss fractions: [0.0085]\n","Episode: 149339, current best loss fractions: [0.0085]\n","Episode: 149344, current best loss fractions: [0.0085]\n","Episode: 149349, current best loss fractions: [0.0085]\n","Episode: 149354, current best loss fractions: [0.0085]\n","Episode: 149359, current best loss fractions: [0.0085]\n","Episode: 149364, current best loss fractions: [0.0085]\n","Episode: 149369, current best loss fractions: [0.0085]\n","Episode: 149374, current best loss fractions: [0.0085]\n","Episode: 149379, current best loss fractions: [0.008]\n","Episode: 149384, current best loss fractions: [0.008]\n","Episode: 149389, current best loss fractions: [0.008]\n","Episode: 149394, current best loss fractions: [0.008]\n","Episode: 149399, current best loss fractions: [0.008]\n","Episode: 149404, current best loss fractions: [0.008]\n","Episode: 149409, current best loss fractions: [0.008]\n","Episode: 149414, current best loss fractions: [0.008]\n","Episode: 149419, current best loss fractions: [0.008]\n","Episode: 149424, current best loss fractions: [0.008]\n","Episode: 149429, current best loss fractions: [0.008]\n","Episode: 149434, current best loss fractions: [0.008]\n","Episode: 149439, current best loss fractions: [0.008]\n","Episode: 149444, current best loss fractions: [0.008]\n","Episode: 149449, current best loss fractions: [0.008]\n","Episode: 149454, current best loss fractions: [0.008]\n","Episode: 149459, current best loss fractions: [0.008]\n","Episode: 149464, current best loss fractions: [0.008]\n","Episode: 149554, current best loss fractions: [0.008]\n","Episode: 149559, current best loss fractions: [0.008]\n","Episode: 149564, current best loss fractions: [0.008]\n","Episode: 149569, current best loss fractions: [0.008]\n","Episode: 149574, current best loss fractions: [0.008]\n","Episode: 149579, current best loss fractions: [0.008]\n","Episode: 149584, current best loss fractions: [0.008]\n","Episode: 149589, current best loss fractions: [0.008]\n","Episode: 149594, current best loss fractions: [0.008]\n","Episode: 149599, current best loss fractions: [0.008]\n","Episode: 149604, current best loss fractions: [0.008]\n","Episode: 149609, current best loss fractions: [0.008]\n","Episode: 149614, current best loss fractions: [0.008]\n","Episode: 149619, current best loss fractions: [0.008]\n","Episode: 149624, current best loss fractions: [0.008]\n","Episode: 149629, current best loss fractions: [0.008]\n","Episode: 149634, current best loss fractions: [0.008]\n","Episode: 149639, current best loss fractions: [0.008]\n","Episode: 149644, current best loss fractions: [0.008]\n","Episode: 149649, current best loss fractions: [0.008]\n","Episode: 149654, current best loss fractions: [0.008]\n","Episode: 149659, current best loss fractions: [0.008]\n","Episode: 149664, current best loss fractions: [0.008]\n","Episode: 149669, current best loss fractions: [0.008]\n","Episode: 149674, current best loss fractions: [0.008]\n","Episode: 149679, current best loss fractions: [0.008]\n","Episode: 149684, current best loss fractions: [0.008]\n","Episode: 149689, current best loss fractions: [0.008]\n","Episode: 149694, current best loss fractions: [0.008]\n","Episode: 149699, current best loss fractions: [0.0075]\n","Episode: 242924, current best loss fractions: [0.0075]\n","Episode: 242929, current best loss fractions: [0.0075]\n","Episode: 242934, current best loss fractions: [0.0075]\n","Episode: 242939, current best loss fractions: [0.0075]\n","Episode: 242944, current best loss fractions: [0.0075]\n","Episode: 242949, current best loss fractions: [0.0075]\n","Episode: 242954, current best loss fractions: [0.0075]\n","Episode: 242959, current best loss fractions: [0.0075]\n","Episode: 242964, current best loss fractions: [0.0075]\n","Episode: 242969, current best loss fractions: [0.0075]\n","Episode: 242974, current best loss fractions: [0.0075]\n","Episode: 242979, current best loss fractions: [0.0075]\n","Episode: 242984, current best loss fractions: [0.007]\n","Episode: 242989, current best loss fractions: [0.007]\n","Episode: 242994, current best loss fractions: [0.007]\n","Episode: 242999, current best loss fractions: [0.007]\n","Episode: 243004, current best loss fractions: [0.007]\n","Episode: 243009, current best loss fractions: [0.007]\n","Episode: 243014, current best loss fractions: [0.007]\n","Episode: 243019, current best loss fractions: [0.007]\n","Episode: 243024, current best loss fractions: [0.007]\n","Episode: 243029, current best loss fractions: [0.007]\n","Episode: 243034, current best loss fractions: [0.007]\n","Episode: 243039, current best loss fractions: [0.007]\n","Episode: 243044, current best loss fractions: [0.007]\n","Episode: 243049, current best loss fractions: [0.007]\n","Episode: 243054, current best loss fractions: [0.007]\n","Episode: 243059, current best loss fractions: [0.007]\n","Episode: 243064, current best loss fractions: [0.007]\n","Episode: 243069, current best loss fractions: [0.007]\n","Episode: 243074, current best loss fractions: [0.007]\n","Episode: 243079, current best loss fractions: [0.007]\n","Episode: 243084, current best loss fractions: [0.007]\n","Episode: 243089, current best loss fractions: [0.007]\n","Episode: 243094, current best loss fractions: [0.007]\n","Episode: 243099, current best loss fractions: [0.007]\n","Episode: 243104, current best loss fractions: [0.007]\n","Episode: 243109, current best loss fractions: [0.007]\n","Episode: 243114, current best loss fractions: [0.007]\n","Episode: 243119, current best loss fractions: [0.007]\n","Episode: 243124, current best loss fractions: [0.007]\n","Episode: 243129, current best loss fractions: [0.0065]\n","Episode: 243134, current best loss fractions: [0.0065]\n","Episode: 243139, current best loss fractions: [0.0065]\n","Episode: 243144, current best loss fractions: [0.0065]\n","Episode: 243149, current best loss fractions: [0.0065]\n","Episode: 243154, current best loss fractions: [0.0065]\n","Episode: 243159, current best loss fractions: [0.0065]\n","Episode: 243164, current best loss fractions: [0.0065]\n","Episode: 243169, current best loss fractions: [0.0065]\n","Episode: 243174, current best loss fractions: [0.0065]\n","Episode: 243179, current best loss fractions: [0.0065]\n","Episode: 243184, current best loss fractions: [0.0065]\n","Episode: 243189, current best loss fractions: [0.0065]\n","Episode: 243194, current best loss fractions: [0.0065]\n","Episode: 243199, current best loss fractions: [0.0065]\n","Episode: 243204, current best loss fractions: [0.0065]\n","Episode: 243209, current best loss fractions: [0.0065]\n","Episode: 243214, current best loss fractions: [0.0065]\n","Episode: 243219, current best loss fractions: [0.0065]\n","Episode: 243224, current best loss fractions: [0.0065]\n","Episode: 243229, current best loss fractions: [0.0065]\n","Episode: 243234, current best loss fractions: [0.0065]\n","Episode: 243239, current best loss fractions: [0.0065]\n","Episode: 243244, current best loss fractions: [0.0065]\n","Episode: 243249, current best loss fractions: [0.0065]\n","Episode: 243254, current best loss fractions: [0.0065]\n","Episode: 243259, current best loss fractions: [0.0065]\n","Episode: 243264, current best loss fractions: [0.0065]\n","Episode: 243269, current best loss fractions: [0.0065]\n","Episode: 243274, current best loss fractions: [0.0065]\n","Episode: 243279, current best loss fractions: [0.0065]\n","Episode: 243284, current best loss fractions: [0.0065]\n","Episode: 243289, current best loss fractions: [0.0065]\n","Episode: 243294, current best loss fractions: [0.0065]\n","Episode: 243299, current best loss fractions: [0.0065]\n","Episode: 243304, current best loss fractions: [0.0065]\n","Episode: 243309, current best loss fractions: [0.0065]\n","Episode: 243314, current best loss fractions: [0.0065]\n","Episode: 243319, current best loss fractions: [0.0065]\n","Episode: 243324, current best loss fractions: [0.0065]\n","Episode: 243329, current best loss fractions: [0.0065]\n","Episode: 243334, current best loss fractions: [0.0065]\n","Episode: 342973, current best loss fractions: [0.0065]\n","Episode: 342978, current best loss fractions: [0.0065]\n","Episode: 342983, current best loss fractions: [0.0065]\n","Episode: 342988, current best loss fractions: [0.0065]\n","Episode: 342993, current best loss fractions: [0.0065]\n","Episode: 342998, current best loss fractions: [0.0065]\n","Episode: 343003, current best loss fractions: [0.0065]\n","Episode: 343008, current best loss fractions: [0.0065]\n","Episode: 343013, current best loss fractions: [0.006]\n","Episode: 343018, current best loss fractions: [0.006]\n","Episode: 343023, current best loss fractions: [0.006]\n","Episode: 343028, current best loss fractions: [0.006]\n","Episode: 343033, current best loss fractions: [0.006]\n","Episode: 343038, current best loss fractions: [0.006]\n","Episode: 343043, current best loss fractions: [0.006]\n","Episode: 343048, current best loss fractions: [0.006]\n","Episode: 343053, current best loss fractions: [0.006]\n","Episode: 343058, current best loss fractions: [0.006]\n","Episode: 343063, current best loss fractions: [0.006]\n","Episode: 343068, current best loss fractions: [0.006]\n","Episode: 343073, current best loss fractions: [0.006]\n","Episode: 343078, current best loss fractions: [0.006]\n","Episode: 343083, current best loss fractions: [0.006]\n","Episode: 343088, current best loss fractions: [0.006]\n","Episode: 343183, current best loss fractions: [0.006]\n","Episode: 343188, current best loss fractions: [0.006]\n","Episode: 343193, current best loss fractions: [0.006]\n","Episode: 343198, current best loss fractions: [0.006]\n","Episode: 343203, current best loss fractions: [0.006]\n","Episode: 343208, current best loss fractions: [0.006]\n","Episode: 343213, current best loss fractions: [0.006]\n","Episode: 343218, current best loss fractions: [0.006]\n","Episode: 343223, current best loss fractions: [0.006]\n","Episode: 343228, current best loss fractions: [0.006]\n","Episode: 343233, current best loss fractions: [0.006]\n","Episode: 343238, current best loss fractions: [0.006]\n","Episode: 343243, current best loss fractions: [0.006]\n","Episode: 343248, current best loss fractions: [0.006]\n","Episode: 343253, current best loss fractions: [0.006]\n","Episode: 343258, current best loss fractions: [0.006]\n","Episode: 343263, current best loss fractions: [0.006]\n","Episode: 343268, current best loss fractions: [0.006]\n","Episode: 343273, current best loss fractions: [0.006]\n","Episode: 343278, current best loss fractions: [0.006]\n","Episode: 343283, current best loss fractions: [0.006]\n","Episode: 343288, current best loss fractions: [0.006]\n","Episode: 343717, current best loss fractions: [0.006]\n","Episode: 343722, current best loss fractions: [0.006]\n","Episode: 343727, current best loss fractions: [0.006]\n","Episode: 343732, current best loss fractions: [0.006]\n","Episode: 343737, current best loss fractions: [0.006]\n","Episode: 343742, current best loss fractions: [0.006]\n","Episode: 343747, current best loss fractions: [0.006]\n","Episode: 343752, current best loss fractions: [0.006]\n","Episode: 343757, current best loss fractions: [0.006]\n","Episode: 343762, current best loss fractions: [0.006]\n","Episode: 343767, current best loss fractions: [0.006]\n","Episode: 343772, current best loss fractions: [0.006]\n","Episode: 343777, current best loss fractions: [0.006]\n","Episode: 343782, current best loss fractions: [0.006]\n","Episode: 343787, current best loss fractions: [0.006]\n","Episode: 343792, current best loss fractions: [0.006]\n","Episode: 343797, current best loss fractions: [0.006]\n","Episode: 367604, current best loss fractions: [0.006]\n","Episode: 367609, current best loss fractions: [0.006]\n","Episode: 367614, current best loss fractions: [0.006]\n","Episode: 367619, current best loss fractions: [0.006]\n","Episode: 367624, current best loss fractions: [0.006]\n","Episode: 367629, current best loss fractions: [0.006]\n","Episode: 367634, current best loss fractions: [0.006]\n","Episode: 367639, current best loss fractions: [0.006]\n","Episode: 367644, current best loss fractions: [0.006]\n","Episode: 367649, current best loss fractions: [0.006]\n","Episode: 367654, current best loss fractions: [0.006]\n","Episode: 367659, current best loss fractions: [0.006]\n","Episode: 367664, current best loss fractions: [0.006]\n","Episode: 367669, current best loss fractions: [0.006]\n","Episode: 367674, current best loss fractions: [0.006]\n","Episode: 497815, current best loss fractions: [0.006]\n","Episode: 497820, current best loss fractions: [0.006]\n","Episode: 497825, current best loss fractions: [0.006]\n","Episode: 497830, current best loss fractions: [0.006]\n","Episode: 497835, current best loss fractions: [0.006]\n","Episode: 497840, current best loss fractions: [0.006]\n","Episode: 497845, current best loss fractions: [0.006]\n","Episode: 498579, current best loss fractions: [0.006]\n","Episode: 498584, current best loss fractions: [0.006]\n","Episode: 498589, current best loss fractions: [0.006]\n","Episode: 498594, current best loss fractions: [0.006]\n","Episode: 498599, current best loss fractions: [0.006]\n","Episode: 498604, current best loss fractions: [0.006]\n","Episode: 498609, current best loss fractions: [0.006]\n","Episode: 498614, current best loss fractions: [0.006]\n","Episode: 498619, current best loss fractions: [0.006]\n","Episode: 498624, current best loss fractions: [0.006]\n","Episode: 498629, current best loss fractions: [0.006]\n","Episode: 498634, current best loss fractions: [0.006]\n","Episode: 498707, current best loss fractions: [0.006]\n","Episode: 498712, current best loss fractions: [0.006]\n","Episode: 498717, current best loss fractions: [0.006]\n","Episode: 498722, current best loss fractions: [0.0055]\n","Episode: 498727, current best loss fractions: [0.0055]\n","Episode: 498732, current best loss fractions: [0.0055]\n","Episode: 498887, current best loss fractions: [0.0055]\n","Episode: 498892, current best loss fractions: [0.0055]\n","Episode: 498897, current best loss fractions: [0.0055]\n","Episode: 498902, current best loss fractions: [0.0055]\n","Episode: 498907, current best loss fractions: [0.0055]\n","Episode: 498912, current best loss fractions: [0.0055]\n","Episode: 498917, current best loss fractions: [0.0055]\n","Episode: 498922, current best loss fractions: [0.0055]\n","Episode: 498927, current best loss fractions: [0.0055]\n","Episode: 498932, current best loss fractions: [0.0055]\n","Episode: 498937, current best loss fractions: [0.0055]\n","Episode: 498942, current best loss fractions: [0.0055]\n","Episode: 498947, current best loss fractions: [0.005]\n","Episode: 498952, current best loss fractions: [0.005]\n","Episode: 498957, current best loss fractions: [0.005]\n","Episode: 498962, current best loss fractions: [0.005]\n","Episode: 498967, current best loss fractions: [0.005]\n","Episode: 498972, current best loss fractions: [0.005]\n","Episode: 498977, current best loss fractions: [0.005]\n","Episode: 498982, current best loss fractions: [0.005]\n","Episode: 498987, current best loss fractions: [0.005]\n","Episode: 498992, current best loss fractions: [0.0045]\n","Episode: 498997, current best loss fractions: [0.0045]\n","Episode: 499002, current best loss fractions: [0.0045]\n","Episode: 499007, current best loss fractions: [0.0045]\n","Episode: 499012, current best loss fractions: [0.0045]\n","Episode: 499017, current best loss fractions: [0.0045]\n","Episode: 499022, current best loss fractions: [0.0045]\n","Episode: 499027, current best loss fractions: [0.0045]\n","Episode: 499032, current best loss fractions: [0.0045]\n","Episode: 499037, current best loss fractions: [0.0045]\n","Episode: 499042, current best loss fractions: [0.0045]\n","Episode: 499047, current best loss fractions: [0.004]\n","Episode: 499052, current best loss fractions: [0.004]\n","Episode: 499057, current best loss fractions: [0.004]\n","Episode: 499062, current best loss fractions: [0.004]\n","Episode: 499067, current best loss fractions: [0.004]\n","Episode: 499072, current best loss fractions: [0.004]\n","Episode: 499077, current best loss fractions: [0.004]\n","Episode: 499082, current best loss fractions: [0.004]\n","Episode: 499087, current best loss fractions: [0.004]\n","Episode: 499092, current best loss fractions: [0.004]\n","Episode: 499097, current best loss fractions: [0.004]\n","Episode: 499102, current best loss fractions: [0.004]\n","Episode: 499107, current best loss fractions: [0.004]\n","Episode: 567038, current best loss fractions: [0.004]\n","Episode: 567043, current best loss fractions: [0.004]\n","Episode: 567048, current best loss fractions: [0.004]\n","Episode: 567053, current best loss fractions: [0.004]\n","Episode: 567058, current best loss fractions: [0.004]\n","Episode: 567063, current best loss fractions: [0.004]\n","Episode: 567068, current best loss fractions: [0.004]\n","Episode: 567073, current best loss fractions: [0.004]\n","Episode: 567078, current best loss fractions: [0.004]\n","Episode: 567083, current best loss fractions: [0.004]\n","Episode: 567088, current best loss fractions: [0.004]\n","Episode: 567093, current best loss fractions: [0.004]\n","Episode: 567098, current best loss fractions: [0.004]\n","Episode: 567103, current best loss fractions: [0.004]\n","Episode: 567108, current best loss fractions: [0.004]\n","Episode: 567113, current best loss fractions: [0.004]\n","Episode: 567118, current best loss fractions: [0.004]\n","Episode: 567123, current best loss fractions: [0.004]\n","Episode: 567128, current best loss fractions: [0.004]\n","Episode: 567133, current best loss fractions: [0.004]\n","Episode: 567138, current best loss fractions: [0.004]\n","Episode: 567143, current best loss fractions: [0.004]\n","Episode: 567148, current best loss fractions: [0.004]\n","Episode: 567153, current best loss fractions: [0.004]\n","Episode: 567158, current best loss fractions: [0.004]\n","Episode: 567163, current best loss fractions: [0.004]\n","Episode: 567168, current best loss fractions: [0.004]\n","Episode: 567173, current best loss fractions: [0.004]\n","Episode: 567178, current best loss fractions: [0.004]\n","Episode: 567183, current best loss fractions: [0.004]\n","Episode: 567188, current best loss fractions: [0.004]\n","Episode: 567193, current best loss fractions: [0.004]\n","Episode: 567198, current best loss fractions: [0.004]\n","Episode: 567203, current best loss fractions: [0.004]\n","Episode: 567208, current best loss fractions: [0.004]\n","Episode: 567213, current best loss fractions: [0.004]\n","Episode: 567218, current best loss fractions: [0.004]\n","Episode: 567223, current best loss fractions: [0.004]\n","Episode: 567228, current best loss fractions: [0.004]\n","Episode: 567233, current best loss fractions: [0.004]\n","Episode: 567238, current best loss fractions: [0.004]\n","Episode: 567243, current best loss fractions: [0.004]\n","Episode: 567248, current best loss fractions: [0.004]\n","Episode: 567253, current best loss fractions: [0.004]\n","Episode: 567258, current best loss fractions: [0.004]\n","Episode: 567263, current best loss fractions: [0.004]\n","Episode: 567268, current best loss fractions: [0.004]\n","Episode: 567273, current best loss fractions: [0.004]\n","Episode: 567278, current best loss fractions: [0.004]\n","Episode: 567283, current best loss fractions: [0.0035]\n","Episode: 567288, current best loss fractions: [0.0035]\n","Episode: 567293, current best loss fractions: [0.0035]\n","Episode: 567298, current best loss fractions: [0.0035]\n","Episode: 567303, current best loss fractions: [0.0035]\n","Episode: 567308, current best loss fractions: [0.0035]\n","Episode: 567313, current best loss fractions: [0.003]\n","Episode: 567318, current best loss fractions: [0.003]\n","Episode: 567323, current best loss fractions: [0.003]\n","Episode: 567328, current best loss fractions: [0.003]\n","Episode: 567333, current best loss fractions: [0.003]\n","Episode: 567338, current best loss fractions: [0.003]\n","Episode: 567343, current best loss fractions: [0.003]\n","Episode: 567348, current best loss fractions: [0.003]\n","Episode: 680878, current best loss fractions: [0.003]\n","Episode: 680883, current best loss fractions: [0.003]\n","Episode: 680888, current best loss fractions: [0.003]\n","Episode: 680893, current best loss fractions: [0.003]\n","Episode: 680898, current best loss fractions: [0.003]\n","Episode: 680903, current best loss fractions: [0.003]\n","Episode: 680908, current best loss fractions: [0.003]\n","Episode: 680913, current best loss fractions: [0.003]\n","Episode: 680918, current best loss fractions: [0.003]\n","Episode: 680923, current best loss fractions: [0.003]\n","Episode: 680928, current best loss fractions: [0.003]\n","Episode: 680933, current best loss fractions: [0.003]\n","Episode: 680938, current best loss fractions: [0.003]\n","Episode: 680943, current best loss fractions: [0.003]\n","Episode: 680948, current best loss fractions: [0.003]\n","Episode: 680953, current best loss fractions: [0.003]\n","Episode: 681177, current best loss fractions: [0.003]\n","Episode: 681182, current best loss fractions: [0.003]\n","Episode: 681353, current best loss fractions: [0.003]\n","Episode: 681358, current best loss fractions: [0.003]\n","Episode: 681363, current best loss fractions: [0.0025]\n","Episode: 681368, current best loss fractions: [0.0025]\n","Episode: 681373, current best loss fractions: [0.0025]\n","Episode: 681378, current best loss fractions: [0.0025]\n","Episode: 681383, current best loss fractions: [0.0025]\n","Episode: 681388, current best loss fractions: [0.0025]\n","Episode: 681393, current best loss fractions: [0.0025]\n","Episode: 681398, current best loss fractions: [0.0025]\n","Episode: 681403, current best loss fractions: [0.0025]\n","Episode: 681408, current best loss fractions: [0.0025]\n","Episode: 681413, current best loss fractions: [0.0025]\n","Episode: 681418, current best loss fractions: [0.0025]\n","Episode: 681423, current best loss fractions: [0.0025]\n","Episode: 681428, current best loss fractions: [0.0025]\n","Episode: 681433, current best loss fractions: [0.0025]\n","Episode: 681438, current best loss fractions: [0.0025]\n","Episode: 681443, current best loss fractions: [0.0025]\n","Episode: 681448, current best loss fractions: [0.0025]\n","Episode: 681453, current best loss fractions: [0.0025]\n","Episode: 681458, current best loss fractions: [0.0025]\n","Episode: 681463, current best loss fractions: [0.0025]\n","Episode: 681468, current best loss fractions: [0.0025]\n","Episode: 681473, current best loss fractions: [0.0025]\n","Episode: 681478, current best loss fractions: [0.0025]\n","Episode: 681483, current best loss fractions: [0.0025]\n","Episode: 681488, current best loss fractions: [0.0025]\n","Episode: 681493, current best loss fractions: [0.0025]\n","Episode: 681498, current best loss fractions: [0.0025]\n","Episode: 681503, current best loss fractions: [0.0025]\n","Episode: 681508, current best loss fractions: [0.0025]\n","Episode: 681513, current best loss fractions: [0.0025]\n","Episode: 681518, current best loss fractions: [0.0025]\n","Episode: 681523, current best loss fractions: [0.0025]\n","Episode: 681528, current best loss fractions: [0.0025]\n","Episode: 681533, current best loss fractions: [0.0025]\n","Episode: 681538, current best loss fractions: [0.0025]\n","Episode: 681543, current best loss fractions: [0.0025]\n","Episode: 681548, current best loss fractions: [0.0025]\n","Episode: 681553, current best loss fractions: [0.0025]\n","Episode: 681558, current best loss fractions: [0.0025]\n","Episode: 681563, current best loss fractions: [0.0025]\n","Episode: 681568, current best loss fractions: [0.0025]\n","Episode: 681573, current best loss fractions: [0.0025]\n","Episode: 681578, current best loss fractions: [0.0025]\n","Episode: 681583, current best loss fractions: [0.0025]\n","Episode: 681588, current best loss fractions: [0.0025]\n","Episode: 681593, current best loss fractions: [0.0025]\n","Episode: 681598, current best loss fractions: [0.0025]\n","Episode: 681603, current best loss fractions: [0.0025]\n","Episode: 681608, current best loss fractions: [0.0025]\n","Episode: 681613, current best loss fractions: [0.0025]\n","Episode: 681618, current best loss fractions: [0.0025]\n","Episode: 681623, current best loss fractions: [0.0025]\n","Episode: 681628, current best loss fractions: [0.0025]\n","Episode: 681633, current best loss fractions: [0.0025]\n","Episode: 681638, current best loss fractions: [0.0025]\n","Episode: 681643, current best loss fractions: [0.0025]\n","Episode: 681648, current best loss fractions: [0.0025]\n","Episode: 681653, current best loss fractions: [0.0025]\n","Episode: 681658, current best loss fractions: [0.0025]\n","Episode: 681663, current best loss fractions: [0.002]\n","Episode: 681668, current best loss fractions: [0.002]\n","Episode: 681673, current best loss fractions: [0.002]\n","Episode: 681678, current best loss fractions: [0.002]\n","Episode: 681683, current best loss fractions: [0.002]\n","Episode: 681688, current best loss fractions: [0.002]\n","Episode: 681693, current best loss fractions: [0.002]\n","Episode: 681698, current best loss fractions: [0.002]\n","Episode: 681703, current best loss fractions: [0.002]\n","Episode: 681708, current best loss fractions: [0.002]\n","Episode: 681713, current best loss fractions: [0.002]\n","Episode: 681718, current best loss fractions: [0.002]\n","Episode: 681723, current best loss fractions: [0.002]\n","Episode: 681728, current best loss fractions: [0.002]\n","Episode: 681733, current best loss fractions: [0.002]\n","Episode: 681738, current best loss fractions: [0.002]\n","Episode: 681743, current best loss fractions: [0.002]\n","Episode: 681748, current best loss fractions: [0.002]\n","Episode: 681753, current best loss fractions: [0.002]\n","Episode: 681758, current best loss fractions: [0.002]\n","Episode: 681763, current best loss fractions: [0.002]\n","Episode: 681768, current best loss fractions: [0.002]\n","Episode: 681773, current best loss fractions: [0.002]\n","Episode: 681778, current best loss fractions: [0.002]\n","Episode: 681783, current best loss fractions: [0.002]\n","Episode: 681788, current best loss fractions: [0.002]\n","Episode: 681793, current best loss fractions: [0.002]\n","Episode: 681798, current best loss fractions: [0.002]\n","Episode: 681803, current best loss fractions: [0.002]\n","Episode: 681808, current best loss fractions: [0.002]\n","Episode: 681813, current best loss fractions: [0.002]\n","Episode: 681818, current best loss fractions: [0.002]\n","Episode: 681823, current best loss fractions: [0.002]\n","Episode: 681828, current best loss fractions: [0.002]\n","Episode: 681833, current best loss fractions: [0.002]\n","Episode: 681838, current best loss fractions: [0.002]\n","Episode: 681843, current best loss fractions: [0.002]\n","Episode: 681848, current best loss fractions: [0.002]\n","Episode: 681853, current best loss fractions: [0.002]\n","Episode: 681858, current best loss fractions: [0.002]\n","Episode: 681863, current best loss fractions: [0.002]\n","Episode: 681868, current best loss fractions: [0.002]\n","Episode: 681873, current best loss fractions: [0.002]\n","Episode: 1129906, current best loss fractions: [0.002]\n","Episode: 1129911, current best loss fractions: [0.002]\n","Episode: 1129916, current best loss fractions: [0.002]\n","Episode: 1129921, current best loss fractions: [0.002]\n","Episode: 1129926, current best loss fractions: [0.002]\n","Episode: 1129931, current best loss fractions: [0.002]\n","Episode: 1129936, current best loss fractions: [0.002]\n","Episode: 1129941, current best loss fractions: [0.002]\n","Episode: 1130255, current best loss fractions: [0.002]\n","Episode: 1130260, current best loss fractions: [0.002]\n","Episode: 1130265, current best loss fractions: [0.002]\n","Episode: 1130270, current best loss fractions: [0.002]\n","Episode: 1130275, current best loss fractions: [0.002]\n","Episode: 1130280, current best loss fractions: [0.002]\n","Episode: 1130323, current best loss fractions: [0.002]\n","Episode: 1130328, current best loss fractions: [0.002]\n","Episode: 1130333, current best loss fractions: [0.002]\n","Episode: 1130359, current best loss fractions: [0.002]\n","Episode: 1130364, current best loss fractions: [0.002]\n","Episode: 1130369, current best loss fractions: [0.002]\n","Episode: 1130374, current best loss fractions: [0.002]\n","Episode: 1130379, current best loss fractions: [0.002]\n","Episode: 1130384, current best loss fractions: [0.002]\n","Episode: 1130389, current best loss fractions: [0.002]\n","Episode: 1130394, current best loss fractions: [0.002]\n","Episode: 1130399, current best loss fractions: [0.002]\n","Episode: 1130404, current best loss fractions: [0.002]\n","Episode: 1130409, current best loss fractions: [0.002]\n","Episode: 1130414, current best loss fractions: [0.002]\n","Episode: 1130419, current best loss fractions: [0.002]\n","Episode: 1130424, current best loss fractions: [0.002]\n","Episode: 1130429, current best loss fractions: [0.002]\n","Episode: 1130434, current best loss fractions: [0.002]\n","Episode: 1130439, current best loss fractions: [0.002]\n","Episode: 1130444, current best loss fractions: [0.002]\n","Episode: 1130449, current best loss fractions: [0.002]\n","Episode: 1130454, current best loss fractions: [0.002]\n","Episode: 1130459, current best loss fractions: [0.002]\n","Episode: 1130464, current best loss fractions: [0.002]\n","Episode: 1130469, current best loss fractions: [0.002]\n","Episode: 1130474, current best loss fractions: [0.002]\n","Episode: 1130479, current best loss fractions: [0.002]\n","Episode: 1130484, current best loss fractions: [0.002]\n","Episode: 1130489, current best loss fractions: [0.002]\n","Episode: 1130494, current best loss fractions: [0.002]\n","Episode: 1314017, current best loss fractions: [0.002]\n","Episode: 1314022, current best loss fractions: [0.002]\n","Episode: 1314027, current best loss fractions: [0.002]\n","Episode: 1314032, current best loss fractions: [0.002]\n","Episode: 1314037, current best loss fractions: [0.002]\n","Episode: 1314042, current best loss fractions: [0.002]\n","Episode: 1314047, current best loss fractions: [0.002]\n","Episode: 1314052, current best loss fractions: [0.002]\n","Episode: 1314057, current best loss fractions: [0.002]\n","Episode: 1397940, current best loss fractions: [0.002]\n","Episode: 1397945, current best loss fractions: [0.002]\n","Episode: 1397950, current best loss fractions: [0.002]\n","Episode: 1397955, current best loss fractions: [0.002]\n","Episode: 1397960, current best loss fractions: [0.002]\n","Episode: 1397965, current best loss fractions: [0.002]\n","Episode: 1397970, current best loss fractions: [0.002]\n","Episode: 1397975, current best loss fractions: [0.002]\n","Episode: 1397980, current best loss fractions: [0.002]\n","Episode: 1397985, current best loss fractions: [0.002]\n","Episode: 1397990, current best loss fractions: [0.002]\n","Episode: 1397995, current best loss fractions: [0.002]\n","Episode: 1398000, current best loss fractions: [0.002]\n","Episode: 1398005, current best loss fractions: [0.002]\n","Episode: 1398010, current best loss fractions: [0.002]\n","Episode: 1398015, current best loss fractions: [0.002]\n","Episode: 1398020, current best loss fractions: [0.002]\n","Episode: 1398025, current best loss fractions: [0.002]\n","Episode: 1398030, current best loss fractions: [0.002]\n","Episode: 1398035, current best loss fractions: [0.002]\n","Episode: 1398040, current best loss fractions: [0.002]\n","Episode: 1398045, current best loss fractions: [0.002]\n","Episode: 1398050, current best loss fractions: [0.002]\n","Episode: 1398055, current best loss fractions: [0.002]\n","Episode: 1398060, current best loss fractions: [0.002]\n","Episode: 1398065, current best loss fractions: [0.002]\n","Episode: 1398070, current best loss fractions: [0.002]\n","Episode: 1398075, current best loss fractions: [0.002]\n","Episode: 1398080, current best loss fractions: [0.002]\n","Episode: 1398085, current best loss fractions: [0.002]\n","Episode: 1398090, current best loss fractions: [0.002]\n","Episode: 1398095, current best loss fractions: [0.002]\n","Episode: 1398100, current best loss fractions: [0.002]\n","Episode: 1398105, current best loss fractions: [0.002]\n","Episode: 1398110, current best loss fractions: [0.002]\n","Episode: 1398115, current best loss fractions: [0.002]\n","Episode: 1398120, current best loss fractions: [0.002]\n","Episode: 1398125, current best loss fractions: [0.002]\n","Episode: 1398130, current best loss fractions: [0.002]\n","Episode: 1398135, current best loss fractions: [0.002]\n","Episode: 1398140, current best loss fractions: [0.002]\n","Episode: 1398145, current best loss fractions: [0.002]\n","Episode: 1398150, current best loss fractions: [0.002]\n","Episode: 1398155, current best loss fractions: [0.002]\n","Episode: 1398160, current best loss fractions: [0.002]\n","Episode: 1398165, current best loss fractions: [0.002]\n","Episode: 1398170, current best loss fractions: [0.002]\n","Episode: 1398175, current best loss fractions: [0.002]\n","Episode: 1398180, current best loss fractions: [0.002]\n","Episode: 1398185, current best loss fractions: [0.002]\n","Episode: 1398190, current best loss fractions: [0.002]\n","Episode: 1398195, current best loss fractions: [0.002]\n","Episode: 1398200, current best loss fractions: [0.002]\n","Episode: 1398205, current best loss fractions: [0.002]\n","Episode: 1398210, current best loss fractions: [0.002]\n","Episode: 1398215, current best loss fractions: [0.002]\n","Episode: 1398220, current best loss fractions: [0.002]\n","Episode: 1398225, current best loss fractions: [0.002]\n","Episode: 1398230, current best loss fractions: [0.002]\n","Episode: 1398235, current best loss fractions: [0.002]\n","Episode: 1398240, current best loss fractions: [0.002]\n","Episode: 1398245, current best loss fractions: [0.002]\n","Episode: 1398250, current best loss fractions: [0.002]\n","Episode: 1398255, current best loss fractions: [0.002]\n","Episode: 1398260, current best loss fractions: [0.002]\n","Episode: 1398265, current best loss fractions: [0.002]\n","Episode: 1398270, current best loss fractions: [0.002]\n","Episode: 1398275, current best loss fractions: [0.002]\n","Episode: 1398280, current best loss fractions: [0.002]\n","Episode: 1398285, current best loss fractions: [0.002]\n","Episode: 1398290, current best loss fractions: [0.002]\n","Episode: 1398295, current best loss fractions: [0.002]\n","Episode: 1398300, current best loss fractions: [0.002]\n","Episode: 1398305, current best loss fractions: [0.002]\n","Episode: 1398310, current best loss fractions: [0.002]\n","Episode: 1398315, current best loss fractions: [0.0015]\n","Episode: 1398320, current best loss fractions: [0.0015]\n","Episode: 1398325, current best loss fractions: [0.0015]\n","Episode: 1398330, current best loss fractions: [0.0015]\n","Episode: 1398335, current best loss fractions: [0.0015]\n","Episode: 1398340, current best loss fractions: [0.0015]\n","Episode: 1398345, current best loss fractions: [0.0015]\n","Episode: 1398350, current best loss fractions: [0.0015]\n","Episode: 1398355, current best loss fractions: [0.0015]\n","Episode: 1398360, current best loss fractions: [0.0015]\n","Episode: 1398365, current best loss fractions: [0.0015]\n","Episode: 1398370, current best loss fractions: [0.0015]\n","Episode: 1398375, current best loss fractions: [0.0015]\n","Episode: 1398380, current best loss fractions: [0.0015]\n","Episode: 1398385, current best loss fractions: [0.0015]\n","Episode: 1398390, current best loss fractions: [0.0015]\n","Episode: 1398395, current best loss fractions: [0.0015]\n","Episode: 1398400, current best loss fractions: [0.0015]\n","Episode: 1398405, current best loss fractions: [0.0015]\n","Episode: 1398410, current best loss fractions: [0.0015]\n","Episode: 1398415, current best loss fractions: [0.0015]\n","Episode: 1398420, current best loss fractions: [0.0015]\n","Episode: 1398425, current best loss fractions: [0.0015]\n","Episode: 1398430, current best loss fractions: [0.0015]\n","Episode: 1398435, current best loss fractions: [0.0015]\n","Episode: 1398440, current best loss fractions: [0.0015]\n","Episode: 1398445, current best loss fractions: [0.001]\n","Episode: 1398450, current best loss fractions: [0.001]\n","Episode: 1712048, current best loss fractions: [0.001]\n","Episode: 1712053, current best loss fractions: [0.001]\n","Episode: 1712058, current best loss fractions: [0.001]\n","Episode: 1712063, current best loss fractions: [0.001]\n","Episode: 1712068, current best loss fractions: [0.001]\n","Episode: 1712073, current best loss fractions: [0.001]\n","Episode: 1712078, current best loss fractions: [0.001]\n","Episode: 1712083, current best loss fractions: [0.001]\n","Episode: 1712205, current best loss fractions: [0.001]\n","Episode: 1712210, current best loss fractions: [0.001]\n","Episode: 1712215, current best loss fractions: [0.001]\n","Episode: 1712220, current best loss fractions: [0.001]\n","Episode: 1712225, current best loss fractions: [0.001]\n","Episode: 1712230, current best loss fractions: [0.001]\n","Episode: 1712235, current best loss fractions: [0.001]\n","Episode: 1712240, current best loss fractions: [0.001]\n","Episode: 1712245, current best loss fractions: [0.001]\n","Episode: 1712285, current best loss fractions: [0.001]\n","Episode: 1712290, current best loss fractions: [0.001]\n","Episode: 1712295, current best loss fractions: [0.001]\n","Episode: 1712300, current best loss fractions: [0.001]\n","Episode: 1712305, current best loss fractions: [0.001]\n","Episode: 1712310, current best loss fractions: [0.001]\n","Episode: 1712315, current best loss fractions: [0.001]\n","Episode: 1712320, current best loss fractions: [0.001]\n","Episode: 1712325, current best loss fractions: [0.001]\n","Episode: 1712330, current best loss fractions: [0.001]\n","Episode: 1712335, current best loss fractions: [0.001]\n","Episode: 1712340, current best loss fractions: [0.001]\n","Episode: 1712345, current best loss fractions: [0.001]\n","Episode: 1712350, current best loss fractions: [0.001]\n","Episode: 1712355, current best loss fractions: [0.001]\n","Episode: 1712360, current best loss fractions: [0.001]\n","Episode: 1712365, current best loss fractions: [0.001]\n","Episode: 1712370, current best loss fractions: [0.001]\n","Episode: 1712375, current best loss fractions: [0.001]\n","Episode: 1712380, current best loss fractions: [0.001]\n","Episode: 1712385, current best loss fractions: [0.001]\n","Episode: 1712390, current best loss fractions: [0.001]\n","Episode: 1712395, current best loss fractions: [0.001]\n","Episode: 1712400, current best loss fractions: [0.001]\n","Episode: 1712405, current best loss fractions: [0.001]\n","Episode: 1712410, current best loss fractions: [0.001]\n","Episode: 1712415, current best loss fractions: [0.001]\n","Episode: 1712420, current best loss fractions: [0.001]\n","Episode: 1712425, current best loss fractions: [0.001]\n","Episode: 1712430, current best loss fractions: [0.001]\n","Episode: 1712435, current best loss fractions: [0.001]\n","Episode: 1712440, current best loss fractions: [0.001]\n","Episode: 1712445, current best loss fractions: [0.001]\n","Episode: 1712450, current best loss fractions: [0.001]\n","Episode: 1712455, current best loss fractions: [0.001]\n","Episode: 1712460, current best loss fractions: [0.001]\n","Episode: 1712465, current best loss fractions: [0.001]\n","Episode: 1712470, current best loss fractions: [0.001]\n","Episode: 1712475, current best loss fractions: [0.001]\n","Episode: 1712480, current best loss fractions: [0.001]\n","Episode: 1712485, current best loss fractions: [0.001]\n","Episode: 1712490, current best loss fractions: [0.001]\n","Episode: 1712495, current best loss fractions: [0.001]\n","Episode: 1712500, current best loss fractions: [0.001]\n","Episode: 1712505, current best loss fractions: [0.001]\n","Episode: 1712510, current best loss fractions: [0.001]\n","Episode: 1712515, current best loss fractions: [0.001]\n","Episode: 1712520, current best loss fractions: [0.001]\n","Episode: 1712525, current best loss fractions: [0.001]\n","Episode: 1712530, current best loss fractions: [0.001]\n","Episode: 1712535, current best loss fractions: [0.001]\n","Episode: 1712540, current best loss fractions: [0.001]\n","Episode: 1712545, current best loss fractions: [0.001]\n","Episode: 1712550, current best loss fractions: [0.001]\n","Episode: 1712555, current best loss fractions: [0.001]\n","Episode: 1712560, current best loss fractions: [0.001]\n","Episode: 1712565, current best loss fractions: [0.001]\n","Episode: 1712570, current best loss fractions: [0.001]\n","Episode: 1712575, current best loss fractions: [0.001]\n","Episode: 1712580, current best loss fractions: [0.001]\n","Episode: 1712585, current best loss fractions: [0.001]\n","Episode: 1712590, current best loss fractions: [0.001]\n","Episode: 1712595, current best loss fractions: [0.001]\n","Episode: 1712600, current best loss fractions: [0.001]\n","Episode: 1712605, current best loss fractions: [0.001]\n","Episode: 1712610, current best loss fractions: [0.001]\n","Episode: 1712615, current best loss fractions: [0.001]\n","Episode: 1712620, current best loss fractions: [0.001]\n","Episode: 1712625, current best loss fractions: [0.001]\n","Episode: 1712630, current best loss fractions: [0.001]\n","Episode: 1712635, current best loss fractions: [0.001]\n","Episode: 1712640, current best loss fractions: [0.001]\n","Episode: 1712645, current best loss fractions: [0.001]\n","Episode: 1712650, current best loss fractions: [0.001]\n","Episode: 1712655, current best loss fractions: [0.001]\n","Episode: 1712660, current best loss fractions: [0.001]\n","Episode: 1712665, current best loss fractions: [0.001]\n","Episode: 1712670, current best loss fractions: [0.001]\n","Episode: 1712675, current best loss fractions: [0.001]\n","Episode: 1712680, current best loss fractions: [0.001]\n","Episode: 1712685, current best loss fractions: [0.001]\n"]}],"source":["def main():\n","\n","    # initialise gym env\n","    env = connect_four_v3.env()\n","    env.reset()\n","    done = False\n","\n","    # initialise memory lists and benchmarks\n","    AI1_mem = clean_memory()\n","    model_list = ['model_0']\n","    model_colours_dict = {'model_0': 'r'}\n","    frac_dict, score_dict = score_dict_init(model_list)\n","    fraction_calc_eps = 2000\n","\n","    #define limits for hyperparameter choices\n","    limits = {'lambda_':(0.95, 0.96), \n","              'gamma':(0.61, 0.62), \n","              'clip':(0.14, 0.15), \n","              'alpha_actor':(0.00025, 0.00026),\n","              'alpha_critic':(0.00025, 0.00026),\n","              'drop_out':(0.0, 0.2)}\n","\n","    # initialise algorithm values\n","    AI1_params = algo_hyperparam_init(limits)\n","    model_iterations = 100\n","    lose_frac = 0\n","    best_frac = [0.01]\n","    model_count = 1\n","    save_count = 0\n","    ep_count = 0\n","    last_change = 0\n","    print_at = 10000\n","    n_epochs = 2\n","    n_actions = 7\n","    batch_size = 64\n","    T = 2048\n","    t = 0\n","    c1 = 0.5\n","    plot = True\n","    colour_plot_list = ['r', 'g', 'b', 'c', 'm', 'y']\n","\n","\n","    # setup initial optimisiers and models\n","    actor_1 = Actor(n_actions, AI1_params['drop_out'])\n","    critic_1 = Critic(AI1_params['drop_out'])\n","    actor_1_optimiser = optim.Adam(actor_1.parameters(), lr=AI1_params['alpha_actor'])\n","    critic_1_optimiser = optim.Adam(critic_1.parameters(), lr=AI1_params['alpha_critic'])\n","\n","    #check size of model\n","    pytorch_total_params = sum(p.numel() for p in actor_1.parameters() if p.requires_grad)\n","    print(pytorch_total_params)\n","\n","    #make directories to store trained models\n","    cwd = os.getcwd()\n","    os.makedirs(f'{cwd}/drive/MyDrive/models')\n","\n","    # iterate through episodes\n","    while model_count != model_iterations:\n","\n","      # reset env at the end of an episode\n","      env.reset()\n","      done = False\n","      AI1_score = 0\n","      AI2_score = 0\n","\n","      # if there is an agent available in memory\n","      # then randomly pick it for the episode \n","      if model_count > 1:\n","          model_choice = f'model_{np.random.randint(0, model_count)}'\n","          if model_choice != 'model_0':\n","              actor_2 = torch.load(f'drive/MyDrive/models/{model_choice}')\n","      else:\n","          model_choice = 'model_0'\n","\n","      # select player agent will play as\n","      A1 = f'player_{np.random.randint(0, 2)}'\n","\n","      # iterate until the end of the episode\n","      while not done:\n","          for agent in env.agent_iter():\n","\n","              # get the last observation\n","              observation, reward, done, _ = env.last()\n","\n","              # if the agent is AI1\n","              if agent == A1:\n","                  \n","                  #update score\n","                  AI1_score += reward\n","\n","                  # boost score if lose\n","                  if reward == 1:\n","                    reward = 0\n","\n","                  #reshape observation for CNN\n","                  reshaped_observation = reshape_image(observation['observation'])\n","\n","                  # choose new action if not done and get obs value for observation\n","                  if not done:\n","                      action, prob = choose_action(   reshaped_observation, \n","                                                      observation['action_mask'], \n","                                                      actor_1\n","                                                      )\n","                      value = torch.squeeze(critic_1(torch.tensor(reshaped_observation))).item()\n","\n","                      # store in memory\n","                      AI1_mem['actions'].append(action)\n","                      AI1_mem['action_masks'].append(observation['action_mask'])\n","                      AI1_mem['obs'].append(np.squeeze(reshaped_observation))\n","                      AI1_mem['probs'].append(prob)\n","                      AI1_mem['values'].append(value)\n","                      AI1_mem['rewards'].append(reward)\n","                      AI1_mem['dones'].append(done)\n","                  \n","                  # if done then only append rewards\n","                  # the rewards should be as a result of taking the action and\n","                  # so should be staggered and appear one later than the action\n","                  else:\n","                      AI1_mem['rewards'].append(reward)\n","                      AI1_mem['dones'].append(done)\n","\n","                      # to achieve the staggering if the episode has ended\n","                      # then delete a zero reward from the episode\n","                      if len(AI1_mem['rewards']) > 2:\n","                          del AI1_mem['rewards'][-2]\n","                          del AI1_mem['dones'][-2]\n","\n","                      # if memory is too small then clear memory and restart new episode\n","                      else:\n","                          # clean memory\n","                          AI1_mem = clean_memory()\n","                          break\n","\n","                  # if T timesteps is reached then train\n","                  if len(AI1_mem['rewards']) % T == 0:\n","\n","                      #get lists\n","                      values = AI1_mem['values']\n","                      rewards = AI1_mem['rewards']\n","                      dones = AI1_mem['dones']\n","                      obs = AI1_mem['obs']\n","                      actions = AI1_mem['actions']\n","                      action_masks = AI1_mem['action_masks']\n","                      probs = AI1_mem['probs']\n","\n","                      # calculate advantages\n","                      advantages = advantage_calc(values, \n","                                                  rewards, \n","                                                  dones, \n","                                                  AI1_params['lambda_'], \n","                                                  AI1_params['gamma'])\n","\n","                      # create random batches\n","                      batches = batch_builder(probs, values, obs, \n","                                              rewards, actions, advantages, \n","                                              action_masks, batch_size\n","                                              )\n","\n","                      # train for n epochs\n","                      for _ in range(n_epochs):\n","                          actor_1, critic_1 = train(actor_1, critic_1, \n","                                                    actor_1_optimiser, \n","                                                    critic_1_optimiser, \n","                                                    batches, \n","                                                    AI1_params['clip'], \n","                                                    c1\n","                                                   )\n","                          \n","                      # clean memory\n","                      AI1_mem = clean_memory()\n","              \n","              # if agent is AI2\n","              else:\n","\n","                  # reshape observation\n","                  reshaped_observation = reshape_image(observation['observation'])\n","\n","                  # update score\n","                  AI2_score += reward\n","\n","                  # choose new action if not done and get obs value for observation\n","                  if not done:\n","\n","                      if model_choice != 'model_0':\n","                          action, prob = choose_action(   reshaped_observation, \n","                                                          observation['action_mask'], \n","                                                          actor_2\n","                                                          )\n","                      else:\n","                          action = rand_action_picker(n_actions, observation)\n","                  \n","              #step in environment\n","              if done:\n","                  env.step(None)\n","              else:\n","                  env.step(action)\n","\n","      # append episode scores to score dict and add to ep count\n","      #score_dict['training_AI'].append(max([0, AI1_score]))\n","      score_dict[model_choice].append(-1 * (min([0, AI1_score])))\n","      ep_count += 1\n","\n","      # calculate the fraction of the last 2000 games won by the training AI\n","      # only compute this past 30 epsiodes to avoid variance of small sample size\n","      current_frac_list = []\n","      for model in list(score_dict.keys()):\n","\n","          if len(score_dict[model]) > 50:\n","\n","              frac_dict[model].append(np.sum(score_dict[model][-fraction_calc_eps:]) \n","                                          / len(score_dict[model][-fraction_calc_eps:]))\n","              current_frac_list.append(frac_dict[model][-1])\n","      \n","      #if better than best fraction save model\n","      if len(score_dict[model]) > 50:\n","          if all(np.array(best_frac) - np.array(current_frac_list) >= 0):\n","            best_frac = current_frac_list\n","            save_count += 1\n","            # save model\n","            torch.save(actor_1, f'drive/MyDrive/models/model_{model_count}')\n","            if save_count % 5 == 0:\n","                print(f'Episode: {ep_count}, current best loss fractions: {best_frac}')\n","        \n","      # if model has only lost by the loss frac set then save model\n","      if all(np.array(current_frac_list) == 0) and len(current_frac_list) > 0:\n","\n","        print(f'episode: {ep_count} , target loss fraction reached')\n","\n","        # save model and add to list\n","        torch.save(actor_1, f'drive/MyDrive/models/model_{model_count}')\n","        model_list.append(f'model_{model_count}')\n","        model_colours_dict[f'model_{model_count}'] = colour_plot_list[np.random.randint(0, len(colour_plot_list))]\n","\n","        plt.figure(figsize=(8, 5))\n","        plt.grid()\n","        plt.xlabel('Episodes')\n","        plt.ylabel(f'fraction of games lost over {fraction_calc_eps} MA')\n","        plt.title('fraction of games lost by the training agent against all trained models')\n","        for model in list(frac_dict.keys()):\n","            plt.plot(range(len(frac_dict[model])), np.array(frac_dict[model]), \n","                      c=model_colours_dict[model],\n","                      label=model)\n","        plt.legend()\n","        plt.show()\n","\n","        # generate fresh model to train\n","        # setup initial optimisiers and models\n","        current_frac_list = []\n","        best_frac = []\n","        for _ in range(len(model_list)):\n","            best_frac.append(0.01)\n","        frac_dict, score_dict = score_dict_init(model_list)\n","        AI1_params = algo_hyperparam_init(limits)\n","        actor_1 = Actor(n_actions, AI1_params['drop_out'])\n","        critic_1 = Critic(AI1_params['drop_out'])\n","        actor_1_optimiser = optim.Adam(actor_1.parameters(), lr=AI1_params['alpha_actor'])\n","        critic_1_optimiser = optim.Adam(critic_1.parameters(), lr=AI1_params['alpha_critic'])\n","\n","        print(f'saved model num: {model_count}')\n","\n","        #add to model count\n","        model_count += 1\n","  \n","      # plot fractions of games won of both agents if plot is true\n","      #if plot and ep_count % print_at == 0 and ep_count > 100:\n","      #    plt.figure(figsize=(8, 5))\n","      #    plt.grid()\n","      #    plt.xlabel('Episodes')\n","      #    plt.ylabel(f'fraction of games lost over {fraction_calc_eps} MA')\n","      #    plt.title('fraction of games lost by the training agent against all trained models')\n","      #    for model in list(frac_dict.keys()):\n","      #        plt.plot(range(len(frac_dict[model])), np.array(frac_dict[model]), \n","      #                 c=model_colours_dict[model],\n","      #                 label=model)\n","      #    plt.legend()\n","      #    plt.show()\n","\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XRtR8OSNpJuy"},"outputs":[],"source":[""]}],"metadata":{"colab":{"background_execution":"on","collapsed_sections":[],"name":"connect_four.ipynb","provenance":[]},"gpuClass":"standard","interpreter":{"hash":"efa8a8b40504b02c34e3a143df9182d33bd2c1d5c2bc00c9d07912f3ce73a0a4"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}